# 2024-25 M&S Project - Group 2

The project aims to simulate bias in data and evaluate how machine learning models trained on biased data behave. Additionally, it will assess different methods to mitigate bias and improve the fairness of the model’s predictions. The main focus is to understand the impact of biased data on a machine learning system and how fairness interventions affect outcomes.

A **MESA** based simulation is defined, to synthetically generate data that showcases a biased weatlh aquisition phenomena in a given society. A model is trained with this data, and we show how the bias is transfered to the model's predictions.

We also show how we can mitigate this issue, using fair preactices.

## Authors
- Ricardo Inácio
- Tomás Maciel

