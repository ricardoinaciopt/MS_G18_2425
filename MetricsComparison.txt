//1 - Base Model

LightGBM Confusion Matrix:
[[ 4191  1764]
 [  499 11148]]
LightGBM Classification Report:
              precision    recall  f1-score   support

           0       0.89      0.70      0.79      5955
           1       0.86      0.96      0.91     11647

    accuracy                           0.87     17602
   macro avg       0.88      0.83      0.85     17602
weighted avg       0.87      0.87      0.87     17602

Performance Metrics for LightGBM:
        Accuracy: 0.8714
        Precision: 0.8634
        Recall: 0.9572
        F1: 0.9079
        ROC AUC: 0.9394
Fairness Metrics:
        Equal Opportunity Difference: 0.957.
        Misclassification Rate: -1.957
Simulation ended at step 100.
Metrics have been calculated and saved.
{"type":"get_step","step":101}


//2 - with education_level

LightGBM Confusion Matrix:
[[ 4535  2000]
 [  617 11546]]
LightGBM Classification Report:
              precision    recall  f1-score   support

           0       0.88      0.69      0.78      6535
           1       0.85      0.95      0.90     12163

    accuracy                           0.86     18698
   macro avg       0.87      0.82      0.84     18698
weighted avg       0.86      0.86      0.86     18698

Performance Metrics for LightGBM:
        Accuracy: 0.8600
        Precision: 0.8524
        Recall: 0.9493
        F1: 0.8982
        ROC AUC: 0.9283
Fairness Metrics:
        Equal Opportunity Difference: 0.949.
        Misclassification Rate: -1.949
{"type":"get_step","step":101}


//3 - with healtcare cost

LightGBM Confusion Matrix:
[[ 4140  1705]
 [  477 11985]]
LightGBM Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.71      0.79      5845
           1       0.88      0.96      0.92     12462

    accuracy                           0.88     18307
   macro avg       0.89      0.84      0.85     18307
weighted avg       0.88      0.88      0.88     18307

Performance Metrics for LightGBM:
        Accuracy: 0.8808
        Precision: 0.8755
        Recall: 0.9617
        F1: 0.9166
        ROC AUC: 0.9345
Fairness Metrics:
        Equal Opportunity Difference: 0.962.
        Misclassification Rate: -1.962


//4 - with education level and healtcare cost

LightGBM Confusion Matrix:
[[ 3741  1560]
 [  604 11073]]
LightGBM Classification Report:
              precision    recall  f1-score   support

           0       0.86      0.71      0.78      5301
           1       0.88      0.95      0.91     11677

    accuracy                           0.87     16978
   macro avg       0.87      0.83      0.84     16978
weighted avg       0.87      0.87      0.87     16978

Performance Metrics for LightGBM:
        Accuracy: 0.8725
        Precision: 0.8765
        Recall: 0.9483
        F1: 0.9110
        ROC AUC: 0.9302
Fairness Metrics:
        Equal Opportunity Difference: 0.948.
        Misclassification Rate: -1.948

// with only healthcare cost but if they dont have money self disease prob +0.1

LightGBM Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.70      0.72      1589
           1       0.79      0.82      0.81      2177

    accuracy                           0.77      3766
   macro avg       0.77      0.76      0.77      3766
weighted avg       0.77      0.77      0.77      3766

Performance Metrics for LightGBM:
        Accuracy: 0.7730
        Precision: 0.7917
        Recall: 0.8241
        F1: 0.8076
        ROC AUC: 0.8669
Fairness Metrics:
        Equal Opportunity Difference: 0.824.
        Misclassification Rate: -1.824

Conclusion: 
Best Model: Scenario 3 (With Healthcare Cost) offers the best balance of performance with the highest F1-score (0.9166), 
high recall (0.9617), and solid ROC AUC (0.9345). 
It also maintains fairness with only slightly higher Equal Opportunity Difference (0.962).
The baseline model (Scenario 1) is close behind, especially in terms of ROC AUC,
 but the model with healthcare cost excels in recall and F1-score, making it a better option overall.